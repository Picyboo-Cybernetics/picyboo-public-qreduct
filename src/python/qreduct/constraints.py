"""Constraint primitives for the Q-Reduct demo pipeline."""

from __future__ import annotations

import hashlib
from dataclasses import dataclass
from typing import Iterable, List, Sequence

from .chunking import Chunk


@dataclass
class ChunkConstraints:
    """Constraints associated with a single chunk."""

    index: int
    digest: str
    syndrome: List[int]
    merkle_path: List[str]


@dataclass
class ConstraintBundle:
    """Complete constraint set for a payload."""

    chunk_size: int
    original_size: int
    parity_matrix: List[List[int]]
    merkle_root: str
    chunks: List[ChunkConstraints]


def sha256_digest(data: bytes) -> str:
    return hashlib.sha256(data).hexdigest()


def derive_parity_matrix(chunk_bits: int, parity_bits: int, seed: bytes = b"demo") -> List[List[int]]:
    """Build a deterministic pseudo-random GF(2) parity matrix.

    The matrix dimensions are ``parity_bits`` x ``chunk_bits``.  Each row is
    generated by hashing a simple counter alongside the provided *seed*.
    """

    if parity_bits <= 0:
        raise ValueError("parity_bits must be positive")

    matrix: List[List[int]] = []
    counter = 0
    while len(matrix) < parity_bits:
        counter_bytes = counter.to_bytes(4, "big")
        digest = hashlib.sha256(seed + counter_bytes).digest()
        bits = []
        for byte in digest:
            for i in range(8):
                bits.append((byte >> (7 - i)) & 1)
        matrix.append(bits[:chunk_bits])
        counter += 1
    return matrix


def compute_syndrome(chunk: Chunk, parity_matrix: Sequence[Sequence[int]]) -> List[int]:
    """Multiply ``parity_matrix`` with the chunk bits over GF(2)."""

    chunk_bits = _bytes_to_bits(chunk.data)
    syndromes: List[int] = []
    for row in parity_matrix:
        total = 0
        for bit, selector in zip(chunk_bits, row):
            total ^= bit & selector
        syndromes.append(total)
    return syndromes


def build_merkle_tree(leaves: Iterable[str]) -> List[List[str]]:
    """Construct a Merkle tree using SHA-256 on hexadecimal leaves."""

    level = [sha256_digest(bytes.fromhex(leaf)) for leaf in leaves]
    if not level:
        return [[], []]

    tree: List[List[str]] = [level]
    while len(level) > 1:
        next_level: List[str] = []
        for i in range(0, len(level), 2):
            left = level[i]
            right = level[i + 1] if i + 1 < len(level) else left
            combined = sha256_digest((left + right).encode("ascii"))
            next_level.append(combined)
        tree.append(next_level)
        level = next_level
    return tree


def merkle_path(tree: List[List[str]], index: int) -> List[str]:
    """Return the Merkle path for ``index`` within ``tree``."""

    path: List[str] = []
    for level in tree[:-1]:
        sibling_index = index ^ 1
        sibling = level[sibling_index] if sibling_index < len(level) else level[index]
        path.append(sibling)
        index //= 2
    return path


def assemble_constraints(chunks: Sequence[Chunk], parity_bits: int = 4) -> ConstraintBundle:
    """Create digest, syndrome and Merkle constraints for ``chunks``."""

    if not chunks:
        raise ValueError("At least one chunk is required")

    chunk_bits = chunks[0].bit_length()
    parity_matrix = derive_parity_matrix(chunk_bits, parity_bits)

    chunk_constraints: List[ChunkConstraints] = []
    merkle_leaves: List[str] = []

    for chunk in chunks:
        digest = sha256_digest(chunk.data)
        merkle_leaves.append(digest)
        syndrome = compute_syndrome(chunk, parity_matrix)
        chunk_constraints.append(
            ChunkConstraints(
                index=chunk.index,
                digest=digest,
                syndrome=syndrome,
                merkle_path=[],  # filled later
            )
        )

    merkle_tree = build_merkle_tree(merkle_leaves)
    root = merkle_tree[-1][0] if merkle_tree[-1] else ""

    for constraint in chunk_constraints:
        constraint.merkle_path = merkle_path(merkle_tree, constraint.index)

    original_size = sum(len(chunk.data) for chunk in chunks)

    return ConstraintBundle(
        chunk_size=len(chunks[0].data),
        original_size=original_size,
        parity_matrix=[list(row) for row in parity_matrix],
        merkle_root=root,
        chunks=chunk_constraints,
    )


def syndrome_to_int(syndrome: Sequence[int]) -> int:
    value = 0
    for bit in syndrome:
        value = (value << 1) | (bit & 1)
    return value


def _bytes_to_bits(data: bytes) -> List[int]:
    bits: List[int] = []
    for byte in data:
        for i in range(8):
            bits.append((byte >> (7 - i)) & 1)
    return bits
